{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import preprocessing\n",
    "from typing import List\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/caitao/Project/dl-localization')\n",
    "from input_output import Default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 The CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    '''The output dimension of the full connnection layer is 100 x 100 = 10000\n",
    "       Assuming the input image is 1 x 100 x 100\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 5)\n",
    "        self.conv2 = nn.Conv2d(8, 32, 5)\n",
    "        self.fc    = nn.Linear(15488, 10000)  # too many labels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Net1(\n  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(8, 32, kernel_size=(5, 5), stride=(1, 1))\n  (fc): Linear(in_features=15488, out_features=10000, bias=True)\n)\n"
    }
   ],
   "source": [
    "model1 = Net1()\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorInputDataset(Dataset):\n",
    "    '''Sensor reading input dataset'''\n",
    "    def __init__(self, root_dir: str, transform=None):\n",
    "        '''\n",
    "        Args:\n",
    "            root_dir:  directory with all the images\n",
    "            labels:    labels of images\n",
    "            transform: optional transform to be applied on a sample\n",
    "        '''\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.length = len(os.listdir(self.root_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length * Default.sample_per_label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        folder   = self.oneDint2twoDstr(int(idx/Default.sample_per_label))\n",
    "        imgname  = str(idx%Default.sample_per_label) + '.png'\n",
    "        img_path = os.path.join(self.root_dir, folder, imgname)\n",
    "        image = imageio.imread(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.twoDstr2oneDint(folder)\n",
    "        sample = {'image':image, 'label':label}\n",
    "        return sample\n",
    "\n",
    "    def oneDint2twoDstr(self, oneDint):\n",
    "        '''convert a one dimension integer index to a two dimension string index'''\n",
    "        x = oneDint // Default.grid_length\n",
    "        y = oneDint % Default.grid_length\n",
    "        return f'({x}, {y})'\n",
    "    \n",
    "    def twoDstr2oneDint(self, twoDstr):\n",
    "        '''convert a two dimension string to a one dimension integet index for the labels'''\n",
    "        twoDstr = twoDstr[1:-1]\n",
    "        x, y = twoDstr.split(',')\n",
    "        x, y = int(x), int(y)\n",
    "        return x*Default.grid_length + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './data/matrix-1'\n",
    "sensor_input_dataset = SensorInputDataset(root_dir = root_dir, transform = T.ToTensor())\n",
    "sensor_input_dataloader = DataLoader(sensor_input_dataset, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device    = torch.device('cuda')\n",
    "model     = model1.to(device)\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()  # criterion is the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch = 0\nt = 0, loss = 9.190359115600586\nt = 100, loss = 9.191838264465332\nt = 200, loss = 9.197484970092773\nt = 300, loss = 9.197670936584473\nt = 400, loss = 9.216283798217773\nt = 500, loss = 9.206048965454102\nt = 600, loss = 9.197667121887207\nt = 700, loss = 9.222134590148926\nt = 800, loss = 9.207505226135254\nt = 900, loss = 9.207732200622559\nt = 1000, loss = 9.205695152282715\nt = 1100, loss = 9.213281631469727\nt = 1200, loss = 9.216551780700684\nt = 1300, loss = 9.214351654052734\nt = 1400, loss = 9.217650413513184\nt = 1500, loss = 9.222225189208984\nt = 1600, loss = 9.217854499816895\nt = 1700, loss = 9.184883117675781\nt = 1800, loss = 9.221495628356934\nt = 1900, loss = 9.221102714538574\nt = 2000, loss = 9.210466384887695\nt = 2100, loss = 9.213089942932129\nt = 2200, loss = 9.192530632019043\nt = 2300, loss = 9.210480690002441\nt = 2400, loss = 9.208732604980469\nt = 2500, loss = 9.2089204788208\nt = 2600, loss = 9.220396995544434\nt = 2700, loss = 9.220514297485352\nt = 2800, loss = 9.21267318725586\nt = 2900, loss = 9.211160659790039\nt = 3000, loss = 9.213705062866211\nt = 3100, loss = 9.212762832641602\nt = 3200, loss = 9.221719741821289\nt = 3300, loss = 9.2114896774292\nt = 3400, loss = 9.218852996826172\nt = 3500, loss = 9.212888717651367\nt = 3600, loss = 9.207330703735352\nt = 3700, loss = 9.221017837524414\nt = 3800, loss = 9.210068702697754\nt = 3900, loss = 9.218977928161621\nt = 4000, loss = 9.207599639892578\nt = 4100, loss = 9.217187881469727\nt = 4200, loss = 9.203730583190918\nt = 4300, loss = 9.201798439025879\nt = 4400, loss = 9.219623565673828\nt = 4500, loss = 9.213823318481445\nt = 4600, loss = 9.220283508300781\nt = 4700, loss = 9.221044540405273\nt = 4800, loss = 9.208468437194824\nt = 4900, loss = 9.20577621459961\nepoch = 1\nt = 0, loss = 9.200785636901855\nt = 100, loss = 9.208819389343262\nt = 200, loss = 9.211593627929688\nt = 300, loss = 9.205798149108887\nt = 400, loss = 9.210332870483398\nt = 500, loss = 9.207754135131836\nt = 600, loss = 9.193711280822754\nt = 700, loss = 9.209346771240234\nt = 800, loss = 9.192098617553711\nt = 900, loss = 9.209859848022461\nt = 1000, loss = 9.216136932373047\nt = 1100, loss = 9.215660095214844\nt = 1200, loss = 9.204401016235352\nt = 1300, loss = 9.207371711730957\nt = 1400, loss = 9.20862865447998\nt = 1500, loss = 9.21566104888916\nt = 1600, loss = 9.220285415649414\nt = 1700, loss = 9.200153350830078\nt = 1800, loss = 9.218006134033203\nt = 1900, loss = 9.2095308303833\nt = 2000, loss = 9.211609840393066\nt = 2100, loss = 9.210949897766113\nt = 2200, loss = 9.215174674987793\nt = 2300, loss = 9.216943740844727\nt = 2400, loss = 9.19564437866211\nt = 2500, loss = 9.220609664916992\nt = 2600, loss = 9.219780921936035\nt = 2700, loss = 9.212054252624512\nt = 2800, loss = 9.20584774017334\nt = 2900, loss = 9.209512710571289\nt = 3000, loss = 9.220013618469238\nt = 3100, loss = 9.208564758300781\nt = 3200, loss = 9.205321311950684\nt = 3300, loss = 9.211492538452148\nt = 3400, loss = 9.208614349365234\nt = 3500, loss = 9.21715259552002\nt = 3600, loss = 9.216296195983887\nt = 3700, loss = 9.217445373535156\nt = 3800, loss = 9.200757026672363\nt = 3900, loss = 9.207027435302734\nt = 4000, loss = 9.21048355102539\nt = 4100, loss = 9.213668823242188\nt = 4200, loss = 9.213985443115234\nt = 4300, loss = 9.218995094299316\nt = 4400, loss = 9.215642929077148\nt = 4500, loss = 9.218990325927734\nt = 4600, loss = 9.208229064941406\nt = 4700, loss = 9.210406303405762\nt = 4800, loss = 9.214158058166504\nt = 4900, loss = 9.21395492553711\nepoch = 2\nt = 0, loss = 9.211289405822754\nt = 100, loss = 9.207082748413086\nt = 200, loss = 9.204026222229004\nt = 300, loss = 9.212793350219727\nt = 400, loss = 9.20605182647705\nt = 500, loss = 9.209793090820312\nt = 600, loss = 9.21905517578125\nt = 700, loss = 9.213979721069336\nt = 800, loss = 9.210650444030762\nt = 900, loss = 9.208741188049316\nt = 1000, loss = 9.208593368530273\nt = 1100, loss = 9.213247299194336\nt = 1200, loss = 9.209859848022461\nt = 1300, loss = 9.216777801513672\nt = 1400, loss = 9.218459129333496\nt = 1500, loss = 9.212525367736816\nt = 1600, loss = 9.200425148010254\nt = 1700, loss = 9.2129487991333\nt = 1800, loss = 9.209163665771484\nt = 1900, loss = 9.215919494628906\nt = 2000, loss = 9.214747428894043\nt = 2100, loss = 9.21867561340332\nt = 2200, loss = 9.20326042175293\nt = 2300, loss = 9.20427131652832\nt = 2400, loss = 9.218806266784668\nt = 2500, loss = 9.215048789978027\nt = 2600, loss = 9.209664344787598\nt = 2700, loss = 9.218225479125977\nt = 2800, loss = 9.213289260864258\nt = 2900, loss = 9.215970993041992\nt = 3000, loss = 9.20804500579834\nt = 3100, loss = 9.212542533874512\nt = 3200, loss = 9.199210166931152\nt = 3300, loss = 9.200780868530273\nt = 3400, loss = 9.208694458007812\nt = 3500, loss = 9.202320098876953\nt = 3600, loss = 9.207332611083984\nt = 3700, loss = 9.211172103881836\nt = 3800, loss = 9.195743560791016\nt = 3900, loss = 9.208497047424316\nt = 4000, loss = 9.206587791442871\nt = 4100, loss = 9.218304634094238\nt = 4200, loss = 9.205164909362793\nt = 4300, loss = 9.205699920654297\nt = 4400, loss = 9.204917907714844\nt = 4500, loss = 9.210651397705078\nt = 4600, loss = 9.213839530944824\nt = 4700, loss = 9.208383560180664\nt = 4800, loss = 9.211431503295898\nt = 4900, loss = 9.21723747253418\nepoch = 3\nt = 0, loss = 9.20250129699707\nt = 100, loss = 9.217599868774414\nt = 200, loss = 9.209039688110352\nt = 300, loss = 9.210872650146484\nt = 400, loss = 9.214247703552246\nt = 500, loss = 9.207623481750488\nt = 600, loss = 9.200606346130371\nt = 700, loss = 9.207222938537598\nt = 800, loss = 9.215103149414062\nt = 900, loss = 9.21512222290039\nt = 1000, loss = 9.213991165161133\nt = 1100, loss = 9.213300704956055\nt = 1200, loss = 9.199950218200684\nt = 1300, loss = 9.204987525939941\nt = 1400, loss = 9.205033302307129\nt = 1500, loss = 9.21462631225586\nt = 1600, loss = 9.202901840209961\nt = 1700, loss = 9.20604133605957\nt = 1800, loss = 9.211575508117676\nt = 1900, loss = 9.206816673278809\nt = 2000, loss = 9.205739974975586\nt = 2100, loss = 9.218060493469238\nt = 2200, loss = 9.218170166015625\nt = 2300, loss = 9.209428787231445\nt = 2400, loss = 9.212087631225586\nt = 2500, loss = 9.2089262008667\nt = 2600, loss = 9.217273712158203\nt = 2700, loss = 9.203524589538574\nt = 2800, loss = 9.210472106933594\nt = 2900, loss = 9.209859848022461\nt = 3000, loss = 9.193628311157227\nt = 3100, loss = 9.215056419372559\nt = 3200, loss = 9.20815372467041\nt = 3300, loss = 9.209588050842285\nt = 3400, loss = 9.203073501586914\nt = 3500, loss = 9.217809677124023\nt = 3600, loss = 9.205704689025879\nt = 3700, loss = 9.212879180908203\nt = 3800, loss = 9.216983795166016\nt = 3900, loss = 9.21487045288086\nt = 4000, loss = 9.218208312988281\nt = 4100, loss = 9.206403732299805\nt = 4200, loss = 9.206762313842773\nt = 4300, loss = 9.208263397216797\nt = 4400, loss = 9.213008880615234\nt = 4500, loss = 9.203536987304688\nt = 4600, loss = 9.217700958251953\nt = 4700, loss = 9.207683563232422\nt = 4800, loss = 9.212298393249512\nt = 4900, loss = 9.199346542358398\nepoch = 4\nt = 0, loss = 9.210663795471191\nt = 100, loss = 9.207576751708984\nt = 200, loss = 9.21194076538086\nt = 300, loss = 9.206799507141113\nt = 400, loss = 9.19726276397705\nt = 500, loss = 9.21230697631836\nt = 600, loss = 9.200821876525879\nt = 700, loss = 9.209134101867676\nt = 800, loss = 9.217215538024902\nt = 900, loss = 9.208836555480957\nt = 1000, loss = 9.213414192199707\nt = 1100, loss = 9.213772773742676\nt = 1200, loss = 9.213785171508789\nt = 1300, loss = 9.201065063476562\nt = 1400, loss = 9.209134101867676\nt = 1500, loss = 9.215747833251953\nt = 1600, loss = 9.207012176513672\nt = 1700, loss = 9.208704948425293\nt = 1800, loss = 9.218318939208984\nt = 1900, loss = 9.217442512512207\nt = 2000, loss = 9.202829360961914\nt = 2100, loss = 9.202436447143555\nt = 2200, loss = 9.203912734985352\nt = 2300, loss = 9.211359977722168\nt = 2400, loss = 9.202696800231934\nt = 2500, loss = 9.21074390411377\nt = 2600, loss = 9.217586517333984\nt = 2700, loss = 9.21177864074707\nt = 2800, loss = 9.20934772491455\nt = 2900, loss = 9.211359024047852\nt = 3000, loss = 9.211090087890625\nt = 3100, loss = 9.20324993133545\nt = 3200, loss = 9.211313247680664\nt = 3300, loss = 9.205491065979004\nt = 3400, loss = 9.203965187072754\nt = 3500, loss = 9.20267391204834\nt = 3600, loss = 9.19570255279541\nt = 3700, loss = 9.21098518371582\nt = 3800, loss = 9.210407257080078\nt = 3900, loss = 9.21674633026123\nt = 4000, loss = 9.205674171447754\nt = 4100, loss = 9.212932586669922\nt = 4200, loss = 9.210288047790527\nt = 4300, loss = 9.19820499420166\nt = 4400, loss = 9.211132049560547\nt = 4500, loss = 9.198970794677734\nt = 4600, loss = 9.19886302947998\nt = 4700, loss = 9.21003532409668\nt = 4800, loss = 9.216120719909668\nt = 4900, loss = 9.2081880569458\n"
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "train_losses = []\n",
    "valid_accs = []\n",
    "best_acc = 0\n",
    "PATH = '/best_model_{}.pt'\n",
    "print_every = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'epoch = {epoch}')\n",
    "    for t, sample in enumerate(sensor_input_dataloader):\n",
    "        model.train()\n",
    "        X = sample['image'].to(device)\n",
    "        y = sample['label'].to(device)\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if t % print_every == 0:\n",
    "            print(f't = {t}, loss = {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = ['cat', 'dog', 'mouse', 'elephant', 'pandas']\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(labels)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
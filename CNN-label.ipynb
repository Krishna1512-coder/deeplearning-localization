{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 The Nueral Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    '''The output dimension of the full connnection layer is 100 x 100 = 10000\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 5)\n",
    "        self.conv2 = nn.Conv2d(8, 32, 5)\n",
    "        self.fc    = nn.Linear(15488, 10000)  # too many labels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Net1(\n  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(8, 32, kernel_size=(5, 5), stride=(1, 1))\n  (fc): Linear(in_features=15488, out_features=10000, bias=True)\n)\n"
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.1285, -0.0877,  0.0446,  0.1646,  0.0601,  0.1542,  0.1711, -0.0726],\n",
      "       requires_grad=True)\n",
      "tensor([ 0.0121, -0.0033,  0.0131, -0.0049,  0.0089,  0.0118,  0.0052,  0.0008])\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.bias)\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Parameter containing:\ntensor([[[[-1.5852e-01,  8.8093e-02,  9.6235e-02,  7.8223e-02,  1.3234e-01],\n          [-2.4708e-02,  1.6623e-01, -1.9751e-01, -1.7086e-01, -1.6195e-01],\n          [-1.3942e-01,  1.7898e-01, -1.2916e-01, -9.0624e-02,  8.3965e-02],\n          [ 1.7228e-01, -1.9016e-01, -1.9948e-01,  1.7751e-01, -1.3037e-01],\n          [ 1.8090e-01,  1.3046e-01, -1.6858e-01, -4.2735e-02,  2.3471e-02]]],\n\n\n        [[[ 4.5685e-02, -1.0702e-01, -1.5650e-02, -6.3088e-02,  1.2501e-01],\n          [ 1.9547e-01, -3.4969e-02,  1.0039e-01,  1.4681e-02, -1.6749e-01],\n          [ 2.5878e-02,  6.6005e-03, -1.3365e-01,  1.1471e-01, -1.7379e-01],\n          [ 4.8008e-02, -6.8053e-02, -2.9220e-02, -1.6074e-01,  1.7478e-01],\n          [ 1.2434e-01,  1.4895e-01,  1.5388e-01,  1.6127e-01, -6.0982e-02]]],\n\n\n        [[[ 1.5571e-01, -1.0260e-01,  5.2808e-02, -9.5466e-02, -1.4221e-01],\n          [ 1.0766e-01,  7.3024e-02,  8.1635e-02,  2.7965e-02, -7.1412e-02],\n          [ 1.6955e-02,  6.1249e-02,  7.5589e-02, -1.0559e-01, -1.2073e-01],\n          [ 2.0231e-02,  1.7234e-01, -5.0417e-02, -1.6636e-01, -1.5738e-01],\n          [-1.0780e-01, -8.3762e-02,  1.5401e-01,  8.5783e-02,  1.2380e-01]]],\n\n\n        [[[ 7.0208e-02,  9.1385e-02,  1.6103e-02,  1.6177e-02,  8.9617e-02],\n          [ 1.4911e-01,  5.1797e-02, -1.8231e-01,  1.9889e-01, -9.6223e-02],\n          [-1.8238e-01, -8.6709e-02,  1.0030e-01, -4.5059e-03, -1.8026e-01],\n          [-4.4938e-02,  1.0626e-01, -1.5323e-02, -1.8932e-01, -1.7345e-01],\n          [ 1.6953e-01, -1.8353e-01, -7.1899e-02, -8.8270e-02, -1.7596e-01]]],\n\n\n        [[[ 3.3122e-02,  5.8746e-02,  4.3895e-02,  1.7482e-01, -4.9698e-02],\n          [-1.7431e-01,  1.7894e-02, -4.6421e-02, -1.4425e-01,  1.1370e-01],\n          [ 2.3491e-02, -1.1627e-01, -6.1759e-02,  4.4264e-02, -1.6550e-01],\n          [-1.6179e-01, -1.2845e-01, -1.6720e-01,  1.9400e-01,  1.7145e-01],\n          [ 1.2566e-02,  9.5335e-02,  1.8251e-01, -5.0969e-03,  1.4744e-01]]],\n\n\n        [[[-7.8885e-02,  1.7522e-01,  2.6844e-02, -1.1034e-01, -1.3909e-01],\n          [ 1.4665e-01,  1.7885e-01, -7.8232e-03,  1.1823e-01,  9.0890e-02],\n          [ 9.1657e-02, -3.1829e-02,  1.0907e-01, -2.2036e-02, -6.5686e-02],\n          [ 1.2693e-01, -1.6653e-01, -1.3238e-01, -1.8194e-01, -1.5609e-01],\n          [-1.8442e-01,  1.3109e-01, -1.4054e-01,  1.3168e-01,  8.0527e-02]]],\n\n\n        [[[-1.4846e-01,  8.8139e-02, -2.0148e-02, -1.1621e-01,  1.5110e-01],\n          [-1.0731e-01, -5.0132e-02, -1.9679e-01,  3.0971e-02,  1.7742e-01],\n          [ 1.1046e-01,  1.8154e-01, -1.1799e-01, -1.7073e-01,  1.1227e-01],\n          [ 6.9693e-02,  1.8472e-01,  7.3124e-02,  1.4601e-01,  1.3533e-01],\n          [-1.4690e-01,  5.4991e-02, -1.1605e-01, -4.4755e-05,  1.1640e-01]]],\n\n\n        [[[ 3.7397e-02,  3.1884e-02,  1.5023e-01, -1.6605e-01, -1.3032e-01],\n          [ 1.2906e-01, -9.6875e-02, -1.2570e-02, -8.9443e-02,  1.4895e-01],\n          [-7.1841e-02, -1.3251e-01,  2.9411e-03, -1.7784e-01,  1.2075e-01],\n          [-7.9798e-02,  1.6815e-02, -8.1347e-02,  1.2386e-01,  9.0077e-02],\n          [ 1.9693e-01,  7.5637e-02, -2.4591e-03, -1.1401e-01, -8.7749e-02]]]],\n       requires_grad=True)\n"
    }
   ],
   "source": [
    "print(net.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Parameter containing:\ntensor([[[[-1.5840e-01,  8.8046e-02,  9.6144e-02,  7.8180e-02,  1.3223e-01],\n          [-2.4678e-02,  1.6609e-01, -1.9732e-01, -1.7077e-01, -1.6179e-01],\n          [-1.3934e-01,  1.7881e-01, -1.2907e-01, -9.0562e-02,  8.3901e-02],\n          [ 1.7219e-01, -1.8992e-01, -1.9932e-01,  1.7732e-01, -1.3027e-01],\n          [ 1.8075e-01,  1.3039e-01, -1.6842e-01, -4.2673e-02,  2.3456e-02]]],\n\n\n        [[[ 4.5648e-02, -1.0683e-01, -1.5629e-02, -6.3007e-02,  1.2484e-01],\n          [ 1.9524e-01, -3.4884e-02,  1.0023e-01,  1.4640e-02, -1.6732e-01],\n          [ 2.5895e-02,  6.6083e-03, -1.3350e-01,  1.1460e-01, -1.7354e-01],\n          [ 4.7931e-02, -6.8008e-02, -2.9222e-02, -1.6058e-01,  1.7459e-01],\n          [ 1.2422e-01,  1.4874e-01,  1.5370e-01,  1.6106e-01, -6.0823e-02]]],\n\n\n        [[[ 1.5563e-01, -1.0252e-01,  5.2802e-02, -9.5414e-02, -1.4211e-01],\n          [ 1.0762e-01,  7.2966e-02,  8.1599e-02,  2.7950e-02, -7.1327e-02],\n          [ 1.6961e-02,  6.1232e-02,  7.5525e-02, -1.0553e-01, -1.2059e-01],\n          [ 2.0206e-02,  1.7223e-01, -5.0386e-02, -1.6619e-01, -1.5728e-01],\n          [-1.0773e-01, -8.3683e-02,  1.5387e-01,  8.5706e-02,  1.2374e-01]]],\n\n\n        [[[ 7.0170e-02,  9.1334e-02,  1.6083e-02,  1.6149e-02,  8.9541e-02],\n          [ 1.4903e-01,  5.1749e-02, -1.8218e-01,  1.9878e-01, -9.6174e-02],\n          [-1.8228e-01, -8.6689e-02,  1.0025e-01, -4.5266e-03, -1.8015e-01],\n          [-4.4930e-02,  1.0624e-01, -1.5317e-02, -1.8921e-01, -1.7336e-01],\n          [ 1.6943e-01, -1.8345e-01, -7.1930e-02, -8.8250e-02, -1.7590e-01]]],\n\n\n        [[[ 3.3101e-02,  5.8741e-02,  4.3893e-02,  1.7473e-01, -4.9696e-02],\n          [-1.7426e-01,  1.7913e-02, -4.6429e-02, -1.4423e-01,  1.1371e-01],\n          [ 2.3507e-02, -1.1620e-01, -6.1705e-02,  4.4278e-02, -1.6553e-01],\n          [-1.6175e-01, -1.2839e-01, -1.6717e-01,  1.9392e-01,  1.7137e-01],\n          [ 1.2548e-02,  9.5292e-02,  1.8251e-01, -5.0878e-03,  1.4734e-01]]],\n\n\n        [[[-7.8831e-02,  1.7515e-01,  2.6824e-02, -1.1028e-01, -1.3899e-01],\n          [ 1.4655e-01,  1.7876e-01, -7.8122e-03,  1.1806e-01,  9.0808e-02],\n          [ 9.1624e-02, -3.1762e-02,  1.0901e-01, -2.2065e-02, -6.5678e-02],\n          [ 1.2685e-01, -1.6637e-01, -1.3230e-01, -1.8185e-01, -1.5595e-01],\n          [-1.8426e-01,  1.3102e-01, -1.4044e-01,  1.3160e-01,  8.0504e-02]]],\n\n\n        [[[-1.4837e-01,  8.8138e-02, -2.0112e-02, -1.1615e-01,  1.5100e-01],\n          [-1.0722e-01, -5.0138e-02, -1.9669e-01,  3.0996e-02,  1.7738e-01],\n          [ 1.1037e-01,  1.8148e-01, -1.1794e-01, -1.7063e-01,  1.1222e-01],\n          [ 6.9648e-02,  1.8464e-01,  7.3083e-02,  1.4590e-01,  1.3521e-01],\n          [-1.4683e-01,  5.4996e-02, -1.1600e-01, -9.8014e-05,  1.1634e-01]]],\n\n\n        [[[ 3.7381e-02,  3.1860e-02,  1.5012e-01, -1.6591e-01, -1.3025e-01],\n          [ 1.2894e-01, -9.6830e-02, -1.2603e-02, -8.9392e-02,  1.4883e-01],\n          [-7.1753e-02, -1.3240e-01,  2.8932e-03, -1.7772e-01,  1.2066e-01],\n          [-7.9726e-02,  1.6841e-02, -8.1305e-02,  1.2382e-01,  9.0035e-02],\n          [ 1.9684e-01,  7.5573e-02, -2.4809e-03, -1.1392e-01, -8.7683e-02]]]],\n       requires_grad=True)\n"
    }
   ],
   "source": [
    "print(net.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # criterion is the loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "optimizer.zero_grad()  # zero the gradient buffers\n",
    "\n",
    "inputt = torch.randn((1, 1, 100, 100))\n",
    "output = net(inputt)\n",
    "target = torch.randn((1, 10000))\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()       # do the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorInputDataset(Dataset):\n",
    "    '''Sensor reading input dataset'''\n",
    "    def __init__(self, root_dir: str, labels: List, transform=None):\n",
    "        '''\n",
    "        Args:\n",
    "            root_dir: directory with all the images\n",
    "            labels:   labels of images\n",
    "            transform: optional transform to be applied on a sample\n",
    "        '''\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.length = len(os.listdir(self.root_dir))\n",
    "        self.labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}